# 零基础入门深度学习(4) - 卷积神经网络 
## 1 前言 什么是卷积神经网络？
> 笼统来说，就是若干卷积层 + Pooling层 + 全连接层组成的神经网络。所用架构模式为INPUT -> [[CONV]*N -> POOL?]*M -> [FC]*K。  

如下图所示  

![卷积神经网络](https://img-blog.csdnimg.cn/936c0687934e46edb2f449af4fce2688.jpeg#pic_center)

### 1.1 Relu激活函数
在最近新的卷积神经网络中，激活函数选择了<</mark>Relu函数</mark>，定义为：$f(x) = max(0,x)$。  
![Relu](https://img-blog.csdnimg.cn/7dfc8df604914becbe0218aa43ba97a8.jpeg#pic_center)  
具有以下优点： 
- 速度快，并且计算代价相对来说很小，比如sigmoid函数需要计算指数和梯度，但是Relu只需要一个max。
- 减轻了梯度消失的问题
- 可以训练更深的网络
- 具有稀疏性：激活率能够刚好满足理想需求  
### 1.2 卷积和全连接有什么不同呢？  
#### 1.2.1 全连接网络  
- 参数数量过大：层数很多，输入层参数很多
- 没有利用像素之间的相对位置信息：有的权重训练起来没什么必要
- 网络层数限制：梯度下降方法很难训练很深的网络  
#### 1.2.2 卷积神经网络  
- 局部连接：不是全连接，因为浪费
- 权值共享：一组连接可以共享一个权重
- 下采样：通过Pooling来减少样本数->减少参数量->提升鲁棒性  
## 2 今天的主角——卷积神经网络（CNN）的展开  
![卷积神经网络](https://img-blog.csdnimg.cn/936c0687934e46edb2f449af4fce2688.jpeg#pic_center)  
### 2.1 具有三维的层结构  
卷积就会得到Feature Map，在上图中的3代表了三套参数，每个Filter可以输入图像进行卷积得到F M，有多少个Filter就能得到多少个Feature Map。  
下采样会得到更小的Feature Map，由Pooling层完成。  
全连接层中的神经元和上一层的Feature中每个神经元相连，并且输出层的神经元也都全相连于上一个全连接层，这样就得到了输出。  
### 2.2 CNN输出值的计算  

#### 2.2.1 卷积层输出




