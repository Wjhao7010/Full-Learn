# 零基础入门深度学习(1) - 感知器（perceptron）

## 1 前言：要学的深度学习到底是什么

> 深度学习就是使用深度神经网络或者其他深度架构的机器学习方法 

![一个简单的神经网络](C:/Users/26968/Desktop/零基础学习深度学习/perceptron/image/一个简单的神经网络.jpg)
- 那什么是深度神经网路呢？

    在神经元中，它们之间有很多连接，这些连接是层与层之间的神经元所建立起来的。分为输入层（最左侧），输出层（最右侧），那中间的就叫做隐藏层啦。
    隐藏层大于2的神经网络就被称为神经网络了。
## 2 提问：什么是神经元？
>神经元，也叫感知器。就是今天的主角。通俗来讲就是对感知器进行一些参数的输入，从而来实现线性回归和分类等问题，像一个f（x），（函数）。

![感知器](https://img-blog.csdnimg.cn/f6e21c896c1a41dfa862e2a49eae9a3b.jpeg#pic_center)
- 感知器中有几个组成部分：  
①输入权值$w_i$，为$x_i$上对应的权值，还有偏置项b  
②激活函数 $f$ （这比较重要）  
③输出

感知器可以用来实现一些简单的例子，比如实现and函数或者or函数，简单的bool运算，还有更厉害的：拟合任何的线性函数或者回归问题，但是有个小注意，<mark>它并不能实现异或运算哦。</mark>  
![这么厉害啊](https://img-blog.csdnimg.cn/1ac3fe4a103947b5b939ad18e6ec3cff.jpeg#pic_center)
## 3 感知器的运行原理
>简单来讲，就是根据一个以权值$w_i$和输入$x_i$和偏置项b为参的函数，但是参数需要进行不断地训练进行调整，来得到和预测值最相符的结果。
>>初始权重项$w_i$和偏置项b都为0，输入之后，利用公式进行参数调整，最后训练完成。

![感知器训公式](https://img-blog.csdnimg.cn/380789a0de48489b8056bdbddeba16f4.jpeg#pic_center)

其中，t为label，即为训练数据的实际值，y为感知器的输出，t-y即为我们所熟知的误差，$η$为学习速率，利用学习速率*误差*输入可以进行参数权值的调整，学习速率*误差可以调整偏置项。

总结来说就是：输入数据，权重，不断训练感知器->啪！训练好了，输出最后结果。
## 4 代码中的相关
### 4.1 代码部分怎么理解呢？
>代码中使用了很多的方法
- 例如：普通预测方法  
```python
def predict(self, input_vec):
        """
        输入向量，之后输出感知器的计算的结果
        """
        # 把input_vec[x1,x2,x3...xi]和weights[w1,w2,w3...wi]对应在一起
        # 变成[(x1*w1),(x2*w2),(x3*w3)...]
        # 对应好后使用map函数分别计算对应xi，wi的乘积
        # 最后用reduce求和
        return self.activator(
            reduce(lambda a, b: a + b,
                   map(lambda xw: xw[0] * xw[1],
                       zip(input_vec, self.weights)),
                   0.0) + self.bias)
```

其中，  
- ①activator为激活函数，其本身具有定义   
- ②lambda 参数：公式（返回），用于写简单的函数，在reduce中进行了迭代
- ③map（使用列表或者元组时，对元素进行数组变换并且返回新的列表）  
    - map函数语法：map(function, iterable, ...)
    function -- 函数  
    iterable -- 一个或多个序列
    - 返回值为迭代器  
    - 
 
```python
Python3.x 实例
>>> def square(x) :         # 计算平方数
...     return x ** 2
...
>>> map(square, [1,2,3,4,5])    # 计算列表各个元素的平方
<map object at 0x100d3d550>     # 返回迭代器
>>> list(map(square, [1,2,3,4,5]))   # 使用 list() 转换为列表
[1, 4, 9, 16, 25]
>>> list(map(lambda x: x ** 2, [1, 2, 3, 4, 5]))   # 使用 lambda 匿名函数
[1, 4, 9, 16, 25]
>>>  
```  
- zip() 函数
    - zip([iterable, ...])
    - 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。
    - 参数说明：iterable -- 一个或多个迭代器
    - 返回元组列表
    - 
```python
#zip示例
>>> a = [1,2,3]
>>> b = [4,5,6]
>>> c = [4,5,6,7,8]
>>> zipped = zip(a,b)     # 返回一个对象
>>> zipped
<zip object at 0x103abc288>
>>> list(zipped)  # list() 转换为列表
[(1, 4), (2, 5), (3, 6)]
>>> list(zip(a,c))              # 元素个数与最短的列表一致
[(1, 4), (2, 5), (3, 6)]

>>> a1, a2 = zip(*zip(a,b))          # 与 zip 相反，zip(*) 可理解为解压，返回二维矩阵式
>>> list(a1)
[1, 2, 3]
>>> list(a2)
[4, 5, 6]
```  
- reduce函数
    - reduce() 函数会对参数序列中元素进行累积
    - 返回单个值
    - 
```python
from functools import reduce

def sum(a, b):
    print(f"a={a}, b={b}, {a} + {b} ={a+b}")
    return a + b


scores = [75, 65, 80, 95, 50]
total = reduce(sum, scores)
print(total)
```  
### 4.2 代码小步骤
>训练感知器
- 如何训练？
- answer：  
    1. 创建并且初始化感知器（init），设置参数以及激活函数（自定义）
    2. 输入向量并且输出感知器的结果（eg：and函数真值表）
    3. 输入对应的训练数据：一组向量、与每个向量对应的label；以及训练轮数和学习率，然后得到每次训练后的更新
    4. 过一遍所有训练数据并且按照感知器规则更新权重返回训练好的感知器（eg：输入的and函数的测试数据训练并迭代10轮，学习速率为0.1）
    5. 最后按照输入，感知器进行对应处理输出最后结果




参考：菜鸟教程


